{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff33b89e",
   "metadata": {},
   "source": [
    "# First Model Rundown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ebf596",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Set Up the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc35607a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#  Mounts Google Colab on Gdrive.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc72139",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Selects our Gdrive we just mounted above\n",
    "%cd /content/gdrive/My Drive\n",
    "\n",
    "# Create our working directory\n",
    "%mkdir HuruAI\n",
    "\n",
    "# Move into the working directory\n",
    "%cd /HuruAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db514626",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# The code below sets us up with some nice formatting for our plots.\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Import the required packages\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88a725c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Preparing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94de35a7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "# Download and transform the training dataset\n",
    "trainset = datasets.MNIST('./Data', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and transform the test dataset\n",
    "testset = datasets.MNIST('./Data', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bb1ed1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_iterator = iter(trainloader)\n",
    "images, labels = train_iterator.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a888ef4",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d991d132",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Defining Our Network Architecture.\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # make sure input tensor is flattened\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.log_softmax(self.fc3(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5203d08a",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebd9662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Model, define the loss and optimizer\n",
    "\n",
    "model = Net()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcc12f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the into a 1-D vector, new shape is (batch size, color channels, total image pixels) \n",
    "\n",
    "images.resize_(64, 1, 784)\n",
    "\n",
    "# alternatively use the code below to automatically load the batch size\n",
    "# images.resize_(images.shape[0], 1, 784)\n",
    "\n",
    "# Make a forward pass through the network\n",
    "image_index = 0\n",
    "probs = model.forward(images[image_index,:])\n",
    "\n",
    "image = images[image_index]\n",
    "plot.image_preds(image.view(1, 28, 28), probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bd27d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Network\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4064382d",
   "metadata": {},
   "source": [
    "## Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3741f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an iterator for the test dataset\n",
    "test_iterator = iter(testloader)\n",
    "images, labels = test_iterator.next()\n",
    "image = images[1]\n",
    "\n",
    "# Test the network \n",
    "probs = torch.exp(model(image))\n",
    "\n",
    "# Plot the image and class probabilities\n",
    "plot.image_preds(image, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fd8af0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
