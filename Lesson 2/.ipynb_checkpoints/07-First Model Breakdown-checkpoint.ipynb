{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6eb4a54",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/HURU-School/HURUAI/blob/main/Lesson%202/07-First%20Model%20Breakdown.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75f0926",
   "metadata": {},
   "source": [
    "# Breaking Down Our First Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6814998",
   "metadata": {},
   "source": [
    "## Setting Up Our Development Enironment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0942bc3",
   "metadata": {},
   "source": [
    "### Mounting Colab to Gdrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0b0e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Mounts Google Colab on Gdrive.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b90b7e2",
   "metadata": {},
   "source": [
    "### Move to Drive, Create a Working Directory and Move into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362321e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selects our Gdrive we just mounted above\n",
    "%cd /content/gdrive/My Drive\n",
    "\n",
    "# Create our working directory\n",
    "%mkdir HuruAI\n",
    "\n",
    "# Move into the working directory\n",
    "%cd /HuruAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d126bf",
   "metadata": {},
   "source": [
    "### Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603ec29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code below sets us up with some nice formatting for our plots.\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ad147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1261a60f",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Define a plot funtion that takes an image and returns it's predicted Class.\n",
    "This part is usually not included here. It can be written on a separate page and imported. But I will leave it here so that we do not have to deal with the complexities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692abdcf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def image_preds(image, probs):\n",
    "    ''' This function is for viewing an image and its predicted class.\n",
    "    '''\n",
    "    probs = probs.data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "    ax1.imshow(image.resize_(1, 28, 28).numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), probs)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    ax2.set_yticklabels(['T-shirt/top',\n",
    "                            'Trouser',\n",
    "                            'Pullover',\n",
    "                            'Dress',\n",
    "                            'Coat',\n",
    "                            'Sandal',\n",
    "                            'Shirt',\n",
    "                            'Sneaker',\n",
    "                            'Bag',\n",
    "                            'Ankle Boot'], size='small');\n",
    "    ax2.set_title('Returned Class Probabilities')\n",
    "    ax2.set_xlim(0, 1.1)\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0208420a",
   "metadata": {},
   "source": [
    "### Preparing the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e68e9bd",
   "metadata": {},
   "source": [
    "#### Defining Our Transforms\n",
    "Transforms are a way to add variety to our data. Common transforms include:\n",
    "  * Centre Crop - Crops a given image at the centre.\n",
    "  * Color Jitter - randomly changing the brightness, hue, saturation or contrast in an image.\n",
    "  * Grayscale - Converts a color image to grascale\n",
    "  * Random Horizontal Flip - Horizontally flips random images in  a dataset  \n",
    "  \n",
    "Feel free to check out the [transforms documentation](https://pytorch.org/vision/stable/transforms.html) here.  \n",
    "There are more transforms than these. You can read more about these transforms and what they do from the torchvision transforms documentation. In addition, we convert the images in our dataset into tensor datatypes and normalize the data as well. Color in a computer is represented as an integer with values between 0 - 255. Normalizing the tensors scales the values thus the model train faster. In the Normalize function, we pass the mean and standard deviation the function will use to normalize the data. In this case, we pass (0.5, 0.5)\n",
    "$$\n",
    "image = (image-mean) / std\n",
    "$$\n",
    "This normalizes the image to a range of [-1, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3a43b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c12b775",
   "metadata": {},
   "source": [
    "#### Downloading the Dataset\n",
    "We then download the dataset and apply the transfomations defined above. Data loaders provide a convenient way to load our datasets. They match each image to its label,  batch the data into the defined batch sizes and shuffle the data everytime the we are going through the dataloader, to reduce bias. Samplers can also be defined here if the dataset is imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b6d013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('./Data', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST('./Data', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf632c4",
   "metadata": {},
   "source": [
    "#### Prepare an iterator\n",
    "We prepare an iterator that will allow us to loop through our data loader, each time picking an image with its corresponding label as shown below\n",
    "```python\n",
    "for image, label in trainloader:\n",
    "    ## What to do with the image and label.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e038d194",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = iter(trainloader)\n",
    "images, labels = train_iterator.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6227abd8",
   "metadata": {},
   "source": [
    "We can then print out an image from the data loader as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26ff9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[9].numpy().squeeze(), cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c52b30",
   "metadata": {},
   "source": [
    "### Building Our Network\n",
    "The network we implemented in our first model is called a _fully connected_ or _dense network_. In this network, each unit in a layer is connected to every other unit in the next layer. The input to this network MUST be a 1-D tensor. Since our images are 2-D tensors i.e (28 * 28 pixels), we need to convert them to 1-D tensors. This process is called [_flattening._ ](https://pytorch.org/docs/stable/generated/torch.flatten.html)We convert the shape from (64, 1, 28, 28) to (64, 784).\n",
    "Similar to the network before, we need 10 output units, one for each class of clothing item we would like to predict. We calculate the probability that the image provided is of any one class or clothing defined in our labels. This is known as a _discrete probability distribution calculated over the classes(clothing) telling us the most likely class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445ffa72",
   "metadata": {},
   "source": [
    "#### The Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb61847d",
   "metadata": {},
   "source": [
    "Our network consists of an input layer, two hidden layers and an output layer. Typically, the network will need to be _deeper_ than this, but we are keeping things simple. Our network will look as below.\n",
    "![Network architecture](../images/Lesson_2/nn.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abcddec",
   "metadata": {},
   "source": [
    "#### Building Our Network Purely from Tensors\n",
    "In this section we will explore building the network purely from weight matrices. Next, we will explore using torch's nn module to build the network. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f11a9c",
   "metadata": {},
   "source": [
    "##### Define our activation function\n",
    "In the first network, we used a ReLU activation function. For this we will switch things up an explore a new activation function, _the sigmoid activation function_. Mathematically, it is expressed as below:\n",
    "$$\n",
    "\\sigma(x) = \\frac{1}{1 + e^{-x}}\n",
    "$$\n",
    "Graphically, the function is represented as below.\n",
    "![Sigmoid Function](../images/Lesson_2/sigmoid.PNG)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c1b946",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize the sigmoid activation function.\n",
    "\n",
    "def activation(x):\n",
    "    return 1/(1+torch.exp(-x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b58f3b",
   "metadata": {},
   "source": [
    "##### Flatten the Input Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8545f266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the input images\n",
    "inputs = images.view(images.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2de0b2",
   "metadata": {},
   "source": [
    "##### Randomly Initialize Our Weights and Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d913fc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Weights and Bias\n",
    "w1 = torch.randn(784, 256)\n",
    "b1 = torch.randn(256)\n",
    "\n",
    "w2 = torch.randn(256, 64)\n",
    "b2 = torch.randn(64)\n",
    "\n",
    "w3 = torch.randn(64, 10)\n",
    "b3 = torch.randn(10)\n",
    "\n",
    "h1 = activation(torch.mm(inputs, w1) + b1)\n",
    "\n",
    "h2 = activation(torch.mm(h1, w2) + b2)\n",
    "\n",
    "out = torch.mm(h2, w3) + b3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc6d49d",
   "metadata": {},
   "source": [
    "##### Calculate Probability Distribution\n",
    "The probability distribution is calculated by applying a _softmax function_ across the 10 classes. Mathematically, this function is represented as below:\n",
    "$$\n",
    "\\Large \\sigma(x_i) = \\cfrac{e^{x_i}}{\\sum_k^K{e^{x_k}}}\n",
    "$$\n",
    "It mashes each input x into a range between 0 and 1, then normalizes the values resulting in a proper distribution with the values all adding up to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33120c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the softmax function\n",
    "\n",
    "def softmax(x):\n",
    "    return torch.exp(x)/torch.sum(torch.exp(x), dim=1).view(-1, 1)\n",
    "\n",
    "probabilities = softmax(out)\n",
    "\n",
    "# Confirm that indeed the shape is (64, 10)\n",
    "print(probabilities.shape)\n",
    "# Confirm that the probabilirs all add up to 1\n",
    "print(probabilities.sum(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c822f7b",
   "metadata": {},
   "source": [
    "#### Building the Network with Pytorch's _nn_ Module\n",
    "Torch provides a handy module called _nn_, that makes building neural networks from scratch pretty easy.\n",
    "First we inherit from the _nn.Module_ class, combine this with *super().__init__* function, will create a python class object with some useful methods and attributes. \n",
    "\n",
    "```python\n",
    "self.hidden = nn.Linear(784, 256)\n",
    "```\n",
    "The line above will create a module for a linear transformation $x\\mathbf{W} + b$, with 784 units as input and 256 units as output. Hidden layer 1 to hidden layer 2's transformation follows a similar approach with 256 units as input and 64 unts as output, as does the output layer, with 64 inputs and 10 outputs. \n",
    "Next we define the sigmoid activation function and the softmax output function. Setting (dim=1) calculates the softmax output across the columns only.\n",
    "The nn module requires a forward function. The function takes an input tensor and passes it through the transformations defines in the *__init__ function*.  \n",
    "**Note:** Order is not particularly important in the *__init__* definition but it is crucial in the forward method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4dc9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Network\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Inputs to hidden layer 1 linear transformation\n",
    "        self.hidden1 = nn.Linear(784, 256)\n",
    "        # Hidden Layer 1 to hidden layer 2 linear transformation\n",
    "        self.hidden2 = nn.Linear(256, 64)\n",
    "        # Output layer, 10 units - one for each item of clothing\n",
    "        self.output = nn.Linear(64, 10)\n",
    "        \n",
    "        # Define sigmoid activation and softmax output \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass the input tensor through each of our operations\n",
    "        x = self.hidden1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.output(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6045b842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the network\n",
    "\n",
    "model = Net()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027ddf9c",
   "metadata": {},
   "source": [
    "#### Building the network using Pytorch's *nn.functional* Module\n",
    "This module provides a more concise way to build the network architecture. This is by far the most common way to build network architectures in pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdf8f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Inputs to hidden layer 1 linear transformation\n",
    "        self.hidden1 = nn.Linear(784, 256)\n",
    "        # Hidden Layer 1 to hidden layer 2 linear transformation\n",
    "        self.hidden2 = nn.Linear(256, 64)\n",
    "        # Output layer, 10 units - one for each item of clothing\n",
    "        self.output = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Hidden layer 1 with sigmoid activation\n",
    "        x = F.sigmoid(self.hidden1(x))\n",
    "        # Hidden layer 2 with sigmoid activation\n",
    "        x = F.sigmoid(self.hidden2(x))\n",
    "        # Output layer with softmax activation\n",
    "        x = F.softmax(self.output(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfc5e6b",
   "metadata": {},
   "source": [
    "##### Weights and Bias Initialization\n",
    "The weights and biases are initialized, from a random distribution function, for you automatically, unlike when we were building purely from tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69411593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the weights and biases initialized\n",
    "\n",
    "print(model.hidden1.weight)\n",
    "print(model.hidden1.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f54fde2",
   "metadata": {},
   "source": [
    "We could also customize how our weights and biases are initialized as shown below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6c3b2e",
   "metadata": {},
   "source": [
    "###### Initializing using a constant value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ac71e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill all the bias values with zero\n",
    "model.hidden1.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0407410",
   "metadata": {},
   "source": [
    "###### Initializing by sampling from a distibution function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3367f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample from random normal with standard dev = 0.03\n",
    "model.hidden1.weight.data.normal_(std=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140038df",
   "metadata": {},
   "source": [
    "##### Making our forward pass through the Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5f881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab some data \n",
    "train_iterator = iter(trainloader)\n",
    "images, labels = train_iterator.next()\n",
    "\n",
    "# Resize images into a 1D vector, new shape is (batch size, color channels, image pixels) \n",
    "images.resize_(64, 1, 784)\n",
    "# or images.resize_(images.shape[0], 1, 784) to automatically get batch size\n",
    "\n",
    "# Forward pass through the network\n",
    "image_index = 0\n",
    "probs = model.forward(images[image_index,:])\n",
    "\n",
    "image = images[image_index]\n",
    "image_preds(image.view(1, 28, 28), probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb7a620",
   "metadata": {},
   "source": [
    "Our Network is not yet trained. As you can see in the plot above, it is just making random guesses. This is because we initialized the weights and biases from a random distribution, hence the random predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d140435",
   "metadata": {},
   "source": [
    "#### Building the Network using the nn.Sequential Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f2848e",
   "metadata": {},
   "source": [
    "The nn.Sequential module is unique in that the input tensor is passed sequentially through the transformations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cb3d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for our network\n",
    "input_size = 784\n",
    "hidden_sizes = [256, 64]\n",
    "output_size = 10\n",
    "\n",
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size),\n",
    "                      nn.Softmax(dim=1))\n",
    "print(model)\n",
    "\n",
    "# Forward pass through the network and display output\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(images.shape[0], 1, 784)\n",
    "probs = model.forward(images[0,:])\n",
    "image_preds(images[0].view(1, 28, 28), probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db97bd6",
   "metadata": {},
   "source": [
    "### Training the Network.\n",
    "Training a neural network, is the process of finding a set of weights that can cause the network architecture to give us the best performance when solving a problem at hand. The network we saw above is not that smart. We train the network by showing it examples of real world data, and adjusting the weights applied to it, such that, it is able to approximate this function. The power of neural networks is that, given enough data and compute capacity, we can train this network, to be able to approximate this function, and any other function for that matter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6718d777",
   "metadata": {},
   "source": [
    "#### Define the loss function\n",
    "To train our network, we first need to have some measure of how well the network is performing. We usually calculate a **loss function**, which measures our prediction error. A common loss function used in regression and binary classification problems is the **mean squared loss**, expressed as below:\n",
    "$$\n",
    "\\large \\ell = \\frac{1}{2n}\\sum_i^n{\\left(y_i - \\hat{y}_i\\right)^2}\n",
    "$$\n",
    "\n",
    "where $n$ is the number of training examples, $y_i$ are the true labels, and $\\hat{y}_i$ are the predicted labels. We will be diving deeper into this loss function, but in the meantime, you can find the [documentation for loss functions](https://pytorch.org/docs/stable/nn.html#loss-functions) here.  \n",
    "By continously minimizing this loss, with respect to the network parameters, we will come up with a set of parameters that will give us a minimal loss. The process of finding this minimum loss is called **gradient descent.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb22d7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Our loss function.\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdafa7a2",
   "metadata": {},
   "source": [
    "#### Calculate Gradients\n",
    "Torch provides a module called **Autograd** to automatically calculate gradients of tensors. These gradients are used to update the parameters for our archtecture. Pytorch will automatically initialize all parameters with *require_grad=True*. After we calculate the loss, we can call `loss.backward()` and the gradients are calculated automatically.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f485ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten Our images so that we can pass them through a fully connected network\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Pass the images through our model to get the probabilities\n",
    "logps = model(images)\n",
    "\n",
    "# Calculate the loss\n",
    "loss = criterion(logps, labels)\n",
    "\n",
    "# Let us view the gradients before and after the backward pass.\n",
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('After backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62761fd2",
   "metadata": {},
   "source": [
    "#### Define Our Optimizer Function\n",
    "Torch also provides an _optim_ package to update the weights with the calculated gradients. Optimizers usually require that we pass the parameters we want to optimize, and a learning rate. More on the learning rate soon.  \n",
    "When we do multiple backward passes, the gradients are accumulated. Hence we need to do a `optimizer.zero_grad()` to zero our gradients after every training pass to remove the gradients from the previous training passes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5171d02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer passing in the parameters and a learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393d8aa3",
   "metadata": {},
   "source": [
    "#### Training Process In Full\n",
    "The process of training a neural network is as below:\n",
    "  * We make a forward pass through the network.\n",
    "  * We take the output of the forward pass and use it to calculate our loss\n",
    "  * We perform a backward pass to calculate our gradients\n",
    "  * We take an optimizer step to update the parameters of our architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b445bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the network Once again to camcel out everything we have just done\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size),\n",
    "                      nn.Softmax(dim=1))\n",
    "\n",
    "# Define Our Loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Define our optimization function\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define the number of iterations on the full dataset to make during the training process\n",
    "epochs = 5\n",
    "\n",
    "# Train the Network\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Flatten our images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # Zero Out the gradients on every training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Calculate the logits(log_probabilies / predictions) generated by the model\n",
    "        output = model(images)\n",
    "        # Calculate our loss\n",
    "        loss = criterion(output, labels)\n",
    "        # Calculate Our gradients to update the model\n",
    "        loss.backward()\n",
    "        # Perform an optimization step to update the parameters(Weights)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track Our loss. It should be decreasing on every iteration\n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962be930",
   "metadata": {},
   "source": [
    "### Testing the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5fd13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = 0\n",
    "accuracy = 0\n",
    "test_losses = []\n",
    "\n",
    "# Turn off gradients for validation, saves memory and computations\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for images, labels in testloader:\n",
    "        # Flatten our images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        # Pass the image through the model and get the logits\n",
    "        logits = model(images)\n",
    "        # Calculate the test loss\n",
    "        test_loss += criterion(logits, labels)\n",
    "        \n",
    "        # Get the classes for each logit\n",
    "        logit_class = torch.exp(logits)\n",
    "        top_p, top_class = logit_class.topk(1, dim=1)\n",
    "        equals = top_class == labels.view(*top_class.shape)\n",
    "        accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "\n",
    "test_losses.append(test_loss/len(testloader))\n",
    "\n",
    "print(\"Test Loss: {:.3f}.. \".format(test_losses[-1]),\n",
    "      \"Test Accuracy: {:.3f}%\".format((accuracy * 100)/len(testloader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c416a03e",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40adc71",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
