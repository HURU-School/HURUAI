{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d6ce223",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/HURU-School/HURUAI/blob/main/Lesson%202/01%20-%20Google%20Colaboratory%20Refresher.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19870e46",
   "metadata": {},
   "source": [
    "# Running Our First Model\n",
    "\n",
    "In this class, we will flip some few things. We will train a neural network first, see the process involved. Then, later on we will dig into the details of how the model works. With this approach, some things might not be clear from the onset. It is Ok. We will fill in the blank spaces as we go. \n",
    "With deep learning, some parts of the code usually change to accomodate the variety of tasks we would like to accomplish, some parts of the code stay the same. I will break down the notebook into afew sections. Thatway, as we go, it will become quite apparent why we may alter some parts of the code to suit a particular task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d3f449",
   "metadata": {},
   "source": [
    "## MNIST Dataset\n",
    "The MNIST dataset was built in the 80's to assist in organizing, sorting and batching of mails at the US Post office. It is a simple dataset of handwritten digits from 0-9. Our task is to read in an image containing a digit and tell what digit is in the image. This dataset\n",
    "The images in the dataset are grayscale images of size 28 * 28 pixels in size. A sample of the images is shown in the figure below.\n",
    "![MNIST](../images/Lesson_2/mnist_image.PNG)\n",
    "The dataset forms a solid foundation to ANN programming, and specifically computer vision. Building a business model from a digit classifier might be a little too old now, but here is a list of amazing solutions that apply the same technology.\n",
    "  * [GreenEye selective sprayer](https://www.youtube.com/watch?v=iCOuTemX_cc) - Agriculture\n",
    "  * [Mashgin Self Checkout System](https://www.youtube.com/watch?v=oXDvMzptyyw) - Retail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130050a0",
   "metadata": {},
   "source": [
    "### Setting Up Our Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd6412d",
   "metadata": {},
   "source": [
    "#### Mounting Colab to Gdrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0e5696",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Mounts Google Colab on Gdrive.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dca6349",
   "metadata": {},
   "source": [
    "#### Move to Drive, Create a Working Directory and Move into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142c727a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selects our Gdrive we just mounted above\n",
    "%cd /content/gdrive/My Drive\n",
    "\n",
    "# Create our working directory\n",
    "%mkdir HuruAI\n",
    "\n",
    "# Move into the working directory\n",
    "%cd /HuruAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcdf3ed",
   "metadata": {},
   "source": [
    "#### Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb47beed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code below sets us up with some nice formatting for our plots.\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c7b4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f19152f",
   "metadata": {},
   "source": [
    "#### Define a plot funtion that takes an image and returns it's predicted Class.\n",
    "This part is usually not included here. It can be written on a separate page and imported. But I will leave it here so that we do not have to deal with the complexities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611967c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preds(image, probs):\n",
    "    ''' This function is for viewing an image and its predicted class.\n",
    "    '''\n",
    "    probs = probs.data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "    ax1.imshow(image.resize_(1, 28, 28).numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), probs)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    ax2.set_yticklabels(np.arange(10))\n",
    "    ax2.set_title('Returned Class Probabilities')\n",
    "    ax2.set_xlim(0, 1.1)\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1de3bf",
   "metadata": {},
   "source": [
    "### Preparing the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f41fa6",
   "metadata": {},
   "source": [
    "#### Downloading the Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e9ff86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "# Download and transform the training dataset\n",
    "trainset = datasets.MNIST('./Data', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and transform the test dataset\n",
    "testset = datasets.MNIST('./Data', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a5c8ca",
   "metadata": {},
   "source": [
    "#### Prepare an Iterator\n",
    "We prepare an iterator so that later on we can load the images with the corresponding label like\n",
    "```python\n",
    "for image, label in trainloader:\n",
    "    ## What to do with the image and label.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8017249",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = iter(trainloader)\n",
    "images, labels = train_iterator.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa9cbfc",
   "metadata": {},
   "source": [
    "Below is how a sample image looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3807ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73482737",
   "metadata": {},
   "source": [
    "### Building the Network\n",
    "Each image in our dataset is 28 * 28 pixels, which makes a total of 784 pixels. There are 10 classes in the dataset(0 - 9). We will be using ReLU activation which is almost always the standard for multiclass classification. More on this later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a490a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Our Network Architecture.\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # make sure input tensor is flattened\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.log_softmax(self.fc3(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96ec29e",
   "metadata": {},
   "source": [
    "### Training the Network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47deb9e",
   "metadata": {},
   "source": [
    "#### Defining Our Model, Loss and Optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9341316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Model, define the loss and optimizer\n",
    "\n",
    "model = Net()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68068669",
   "metadata": {},
   "source": [
    "#### Dry Run on the network before Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604999ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the into a 1-D vector, new shape is (batch size, color channels, total image pixels) \n",
    "\n",
    "images.resize_(64, 1, 784)\n",
    "\n",
    "# alternatively use the code below to automatically load the batch size\n",
    "# images.resize_(images.shape[0], 1, 784)\n",
    "\n",
    "# Make a forward pass through the network\n",
    "image_index = 0\n",
    "probs = model.forward(images[image_index,:])\n",
    "\n",
    "image = images[image_index]\n",
    "image_preds(image.view(1, 28, 28), probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dd795e",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Train the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c4f8ab",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Training the Network\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9993d8",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Testing the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86557af7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create an iterator for the test dataset\n",
    "test_iterator = iter(testloader)\n",
    "images, labels = test_iterator.next()\n",
    "image = images[1]\n",
    "\n",
    "# Test the network \n",
    "probs = torch.exp(model(image))\n",
    "\n",
    "# Plot the image and class probabilities\n",
    "image_preds(image, probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103ee0b0",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3219da01",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
