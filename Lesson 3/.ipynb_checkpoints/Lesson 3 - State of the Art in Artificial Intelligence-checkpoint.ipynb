{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19c2e2c8",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/HURU-School/HURUAI/blob/main/Lesson%203/Lesson%203%20-%20State%20of%20the%20Art%20in%20Artificial%20Intelligence.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8335e11",
   "metadata": {},
   "source": [
    "# State of the Art in Artificial Intelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc0579e",
   "metadata": {},
   "source": [
    "Every company claims that its artificial intelligence algorithms are the best, the next generation, cutting edge, blah! blah! blah!, you've heard the big words. It gets too complex to tell which is really the best. In academia however, state of the art has real meaning to it. \"The best documented, peer-reviewed results obtained on a problem for a reproducible benchmark.\" \n",
    "For a solution to be considered state of the art, it needs to satisfy these simple benchmarks:\n",
    "1. **It should be peer-reviewed.** It needs to provide the best results on benchmarks that are public, reproducible and trainable.\n",
    "2. **It should be open.** The material portion of the codebase should be available for others to inspect. It does not need to be freely available though. It can be availed on a permissive licence.\n",
    "\n",
    "We will be focussing on the state of the art algorithms in Computer Vision, Natural language processing and Speech Recognition.\n",
    "\n",
    "A great resource to update yourself on the current state of the art models is [papers with code](https://paperswithcode.com/sota). Here you will find research papers and code implementations for these models and get a better understanding of how they work underneath the hood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41409cc",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b1dff1",
   "metadata": {},
   "source": [
    "This is a paradigm of A.I where a model is trained on one task and later repurposed on a different but related task.\n",
    "\n",
    "Steps in transfer learning include:\n",
    "  * Select a source task – preferably with an abundance of data.\n",
    "  * Develop a source model – ideally with some feature learning task performed.\n",
    "  * Reuse the model – source model applied as a starting point.\n",
    "  * Tune the model – Refined on the new dataset.\n",
    "  \n",
    "Benefits of transfer learning include:\n",
    "  * A higher start.\n",
    "  * A higher slope.\n",
    "  * Higher asymptote."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bb7d63",
   "metadata": {},
   "source": [
    "## Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448659ce",
   "metadata": {},
   "source": [
    "Computer vision can be broken down into *Semantic Segmentation*, *image classification* and *Object detection*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a86054",
   "metadata": {},
   "source": [
    "### Semantic Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a83db4d",
   "metadata": {},
   "source": [
    "Semantic segmentation models help to understand the components and structure of an image on a pixel level.\n",
    "The current state of the art model is **HRNet-OCR** that was presented by Tao et. al from Nvidia.\n",
    "Follow the project on its [official github account](https://github.com/HRNet/HRNet-Semantic-Segmentation).\n",
    "\n",
    "Other top-tier solutions include:\n",
    "1. [Efficient-Net-L2+NAS-FPN — PASCAL VOC](https://arxiv.org/pdf/2006.06882v1.pdf)\n",
    "2. [ResNeSt-269 — PASCAL Context](https://arxiv.org/pdf/2004.08955v1.pdf)\n",
    "3. [VMVF —ScanNet](https://arxiv.org/pdf/2007.13138v1.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4d2aed",
   "metadata": {},
   "source": [
    "### Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0197d724",
   "metadata": {},
   "source": [
    "This methodology focusses on the image as a whole.. The current state of the art model is **EfficientNet - L2** presented by the **Google Research Team**. When run on the ImageNet dataset it produces a top-1 accuracy of **90.2%.**\n",
    "\n",
    "Notable competitors in this category include:\n",
    "1. [BiT-L](https://arxiv.org/pdf/1912.11370v3.pdf) — CIFAR-10\n",
    "2. [Wide-ResNet-101](https://arxiv.org/pdf/2007.03347v2.pdf) — STL-10\n",
    "3. [Branching/Merging CNN + Homogeneous Filter Capsules](https://arxiv.org/pdf/2001.09136v4.pdf) — MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6209c47e",
   "metadata": {},
   "source": [
    "### Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15094a82",
   "metadata": {},
   "source": [
    "Object detection involves recognizing instances of objects in an image.Currently, the leading object detection model is **Efficient-Det D7x** presented by the **Google Brain Team**. It combines EfficientNets with Bidirectional Feature Pyramid Networks(BiFPNs). It achieved an AP50 of **74,3** and a box AP of **55,1**.\n",
    "\n",
    "Other top-notch algorithms include:\n",
    "1. [RODEO](https://arxiv.org/pdf/2008.06439v1.pdf) — PASCAL VOC\n",
    "2. [Patch Refinement](https://arxiv.org/pdf/1910.04093v1.pdf) — KITTI Cars Easy\n",
    "3. [IterDet](https://arxiv.org/pdf/2005.05708v1.pdf) — CrowdHuman"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5a42d9",
   "metadata": {},
   "source": [
    "## Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d252f3",
   "metadata": {},
   "source": [
    "This is a field of AI that powers machines with the capacity to read, understand and derive meaning from human languages. It is broadly broken down into *Sentiment Analysis*, *Language Modelling*, *Machine Translation*, *Text Classification* and *Question Answering*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ab88e0",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf5ba36",
   "metadata": {},
   "source": [
    "This field is used to interprete and classify emotions in a block of text data. The current leading algorithm is **BERT**, developed by the **Google AI Team**, which attained an accuracy of **55.5** when tested on the SST-5 Fine-grained classification dataset.\n",
    "\n",
    "Other notable top-tier techniques include:\n",
    "1. [T5–3B](https://arxiv.org/pdf/1910.10683v3.pdf) — SST-2 Binary classification\n",
    "2. [NB-weighted-BON + dv-cosine](https://paperswithcode.com/paper/sentiment-classification-using-document) — IMDb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44faf66",
   "metadata": {},
   "source": [
    "### Language Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a1f50e",
   "metadata": {},
   "source": [
    "Language modelling tasks involve predicting the next words or letters based on the previous words. The current state of the art model is Megatron-LM, developed by the Nvidia team. It achieved a score of **10.8** when tested on the WikiText103.\n",
    "\n",
    "Other notable top-tier techniques include:\n",
    "1. [GPT-3](https://arxiv.org/pdf/2005.14165v4.pdf) — Penn Treebank\n",
    "2. [GPT-2](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf) — WikiText2, Text8, enwik8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa31b7f5",
   "metadata": {},
   "source": [
    "### Machine Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0ad87c",
   "metadata": {},
   "source": [
    "This is the task of translating text from one language to another. The **Transformer Big +BT** developed by the **Google Brain Team**\n",
    "\n",
    "Other notable top-tier techniques include:\n",
    "1. [MAT+Knee](https://arxiv.org/pdf/2003.03977v1.pdf) — IWSLT2014 German-English\n",
    "2. [MADL](https://openreview.net/pdf?id=HyGhN2A5tm) — WMT2016 English-German\n",
    "3. [Attentional encoder-decoder +BPE](https://arxiv.org/pdf/1606.02891v2.pdf) — WMT2016 German-English"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9000dbe4",
   "metadata": {},
   "source": [
    "### Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a222efe",
   "metadata": {},
   "source": [
    "This is the task of assigning a category to a block of text or sentence. The current state of the art model is **XLNet** developed by the **Google AI Team**. it utilizes a method known as *Permutation Language Modelling*.\n",
    "\n",
    "Other notable top-tier techniques include:\n",
    "1. [USE_T + CNN](https://arxiv.org/pdf/1803.11175v2.pdf) — TREC-6\n",
    "2. [SGC](https://arxiv.org/pdf/1902.07153v2.pdf) — 20News"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8196a2d2",
   "metadata": {},
   "source": [
    "### Question Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5798d023",
   "metadata": {},
   "source": [
    "This is the task of training an algorithm to answer questions.The **T5-11B** algorithm developed by the **Google AI Team** is currently the leading model for this task after producing benchmark results on four different datasets: Glue, SuperGlue, SQuAD and CNN/Daily Mail.\n",
    "\n",
    "Other notable top-tier techniques include:\n",
    "1. [T5–11B](https://arxiv.org/pdf/1910.10683v3.pdf) — SQuAD1.1 dev\n",
    "2. [TANDA-RoBERTa](https://arxiv.org/pdf/1911.04118v2.pdf) — WikiQA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83448f8e",
   "metadata": {},
   "source": [
    "## Recommendation Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fabfbb9",
   "metadata": {},
   "source": [
    "This algorithm will suggest new items that might be of interest to a user based on your past interests. The currently leading algorithm for this task is the **Bayesian Time SVD++**, developed by the **Google AI Team**.\n",
    "\n",
    "Other notable top-tier techniques include:\n",
    "1. [H+Vamp Gated](https://arxiv.org/pdf/1911.00936v1.pdf) — MovieLens 20M\n",
    "2. [EASE](https://arxiv.org/pdf/1905.03375v1.pdf) — Million Song Dataset\n",
    "3. [Bayesian timeSVD++ flipped w/ Ordered Probit Regression](https://arxiv.org/pdf/1905.01395v1.pdf) — MovieLens 1M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae3753d",
   "metadata": {},
   "source": [
    "## Speech Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87965219",
   "metadata": {},
   "source": [
    "Speech recognition tasks help to interprete and derive meaning from voice data. it is used in applications such as *Siri* and *Cortana*. The **ContextNet + SpecAugment-based Noisy Student Training with Libri-Light** algorithm developed by the **Google AI Team** is currently the state of the art solution for this task.\n",
    "\n",
    "Other notable top-tier techniques include:\n",
    "1. [ResNet + BiLSTMs acoustic model](https://arxiv.org/pdf/1703.02136v1.pdf) — Switchboard + Hub500\n",
    "2. [LiGRU + Dropout + BatchNorm + Monophone Reg](https://arxiv.org/pdf/1811.07453v2.pdf) — TIMIT\n",
    "3. [Large-10h-LV-60k — Libri-Light test](https://arxiv.org/pdf/2006.11477v2.pdf) - clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc27fc3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
